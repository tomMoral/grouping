\documentclass{gretsi}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb}
\usepackage[english,francais]{babel}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
%\usepackage{enumitem}


%Gummi|065|=)
\title{Separation de sources automatique}
\author{Thomas Moreau}
\date{}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother
\def\HH{\mathcal H}

\resumefrancais{Cet article introduit différentes stratégies de groupement automatique pour les composantes issues d'une analyse du spectre singulier (SSA). Cette étape, cruciale à la séparation de composantes haut niveau, permet de séparer les différentes effets présents dans le signal. }
\resumeanglais{This paper introduce automatic grouping strategies for Singular Spectrum Analysis (SSA) components. This step is crucial to get meaningful results}

\begin{document}

\maketitle


\section{Introduction}

L'analyse du spectre singulier est une technique très utile pour l'analyse de séries temporelles. Elle permet d'obtenir de manière simple une décomposition du signal en composantes de tendance, composantes oscillantes et bruit. Cette décomposition est utilisée pour l'étude de signaux en finance ou en biologie car elle permet de mettre en avant des périodicités non évidentes dans la série de départ et de les séparer d'autre phénomènes pour pouvoir les étudier.\\


Cependant, cette technique est encore peu utilisé du fait de son manque d'automatisation. En effet, la plupart des utilisations faites se basent sur la sélection manuelle de certains paramètres, notamment le regroupement de certaines composantes entre elles. Ce regroupement est critique car sans lui, un même phénomène peu se retrouver retrouver sur plusieurs des composantes fournies, ce qui complique l'analyse des résultats.\\

Dans cet article, nous étudions différentes stratégies de regroupement présentées dans la littérature. Celles-ci sont comparées à nos propres techniques.

\subsection{SSA}

L'analyse du spectre singulier (SSA) est une technique introduite par Vautard et al \cite{vautard_ghil_89_SSA} pour l'analyse de la dynamique de séries temporelles. Cette technique, basée sur le théorème de Karhunen-Loève, permet de décomposer un signal en une somme de composante haut niveau rattachées à sa tendance et à sa saisonalité.

\paragraph{Matrices de trajectoires}

On considère un signal fini échantillonné $f = (f_n)_{1 \le n\le T}$ et un entier $K \in \left \{ 1, \dots, T/2 \right \}$. La matrice de K-trajectoire $X^{(K)} \in \mathbb{R}^{K\times L}$ est défini par:
$$ X^{(K)} = \begin{bmatrix}
	f_1 & f_2 &\dots & f_K\\
	f_2 & f_3 &\dots & f_{K+1}\\
	\dots\\
	f_{L} & f_{T-K+1} &\dots & f_T
\end{bmatrix}$$
Cette matrice contient toutes les sous fenêtres de longueur $K$ de $f$.\\

Le signal peut être reconstruit naturellement à partir de cette matrice du fait de sa structure de Hankel. Si l'on considère une matrice $M$ n'ayant pas cette structure, le signal ayant la matrice de trajectoire la plus proche de $M$ peut être construit en moyennant le long des anti-diagonales. Cette opération permet de définir un mapping entre l'espace des matrices et celui des signaux. On notera par la suite $\HH$ l'opération de moyennage le long des diagonales.

\paragraph{Extraction de motifs}

Une décomposition en valeur singulière (SVD) de la matrice de K-trajectoire $X^{(K)}$ de $f$ permet d'extraire les motifs de longueur $K$ les plus intéressant. En effet, la SVD donne: 
$$
X^{(K)} = U D V^T
$$ avec $U, V$ deux matrices orthogonales et $D$ une matrice diagonale. $U$ peut alors être vu comme un dictionnaire de motifs de taille $K$ sur lequel est projeté le signal. Ces motifs permettent de capturer au mieux la variance du signal. En effet, les vecteurs singuliers de la SVD maximisent la covariance de $U_i$ et des $X_i$.

\paragraph{Reconstruction de composantes}

L'étape d'extraction de motif permet d'obtenir une décomposition de la matrice de trajectoire sous la forme d'une somme de matrice de rang 1:$$
X^{(K)} = \sum_{i=1}^K \lambda_i U_iV_i^T 
$$A partir de cette décomposition, on considère les séries temporelles $f^{(i)} = \HH(\lambda_iU_iV_i^T)$ pour $i \in \left \{ 1,\dots, m \right \}$ résultantes de l'opération d'hankelisation des matrices de \mbox{rang 1}. Ces composantes ne sont pas toutes utiles car certaines sont du bruit. Une sélection des composantes peut être fait en se basant sur les valeurs singulières associées. De plus, ces composantes peuvent avérées redondantes, séparant un même effet. Une étape de regroupement est alors nécessaire pour obtenir une décomposition utile.\\

Le regroupement consiste à trouver un ensemble $(I_k)_{1 \le k \le d}$ tel que $\forall k, j$, $I_k \cap I_j = \emptyset$ and $\displaystyle \cup_{k=1}^d I_k = I$. Les composantes ainsi créées sont alors $x$


\subsection{Automatisation}
\label{sub:}

% subsection  (end)

\section{Regroupement automatique}

\subsection{Formulation générale}
\label{sub:form}

Les stratégies de regroupement se définissent comme
\begin{enumerate}
	\item Séléctioner m composantes de la SSA
	\item Calculer la similarité entre chacune d'elles
	\item Regrouper les composantes qui sont similaires
\end{enumerate}
L'étape 1 consiste à filtrer les composantes de la SVD ayant une valeur singulières plus faible que $\tau_l*\lambda_1$. Ceci permet d'éliminer les composantes de bruits. La fonction \texttt{Up} permet de définir comment la stratégie considère les différentes composantes. On fixe pour toutes les expériences $\tau_l = 0.01$\\

peuvent être résumé sous une même forme, présentée dans \mbox{l'Algorithme \ref{alg:gen}}. Il est alors nécessaire de choisir 3 paramètres: $\tau_l \in \left[0, 1\right]$, $\texttt{Sim}: \left \{ 1, \dots m \right \}^2 \to \left \{ 0,1 \right \}$ une fonction de similarité entre les composantes et $\texttt{Up}$ une fonction d'actualisation des groupes.\\

% subsection form (end)

Le paramètre $\tau_l$ Une première solution est de considérer que toutes les composantes obtenues avec la SSA ont le même poids. Ainsi, les composantes $i$ et $j$ seront grouper si $\texttt{Sim}(i, j) = 1$. Cette solution ne tient pas compte de l'importance relative des composantes, qui peut être mesurer par la valeur singulière associée. Un autre choix pour la fonction \texttt{Up} est de considérer qu'un groupe est lié à la composante avec la plus grande value singulière. Chaque groupe est alors formé de sorte que si $I_k = \left\{j | \texttt{Sim}(j, i) = 1\right\}$ où $i = \arg\max_{j\in I_k} \lambda_j$. Ce regroupement met en avant la prépondérance de la composantes de plus haute valeur singulière.\\

La fonction \texttt{Sim} est la fonction qui définie la stratégie de regroupement des composantes. Elle permet d'obtenir une matrice d'adjacence entre les composantes qui servira à décider de regrouper ou non deux séries.\\

\subsection{Stratégie de clustering}
\label{sub:}

% subsection  (end)

\subsection{Mesures de similarité}
\label{sub:}

% subsection  (end)

\subsubsection{Corrélation}

\paragraph{Abalov (GG1)}
\label{par:}
La métrique de similarité proposée par les auteurs de \cite{abalov_14_aut} repose sur deux points. Tout d'abord, le ratio des valeurs singulières associées aux signaux considérés doit être proche 1. Ceci implique que l'on ne peut pas regrouper des composantes trop éloignées, pour éviter de grouper des phénomènes présents dans la séries 'ayant pas les même amplitudes. Cet effet est controlé par un seuil $\rho_1$. Ensuite, deux composantes sont regroupées si la corrélation entre elles est plus haute qu'une valeur seuil $\rho_c$:
$$
\texttt{Sim}(i, j) = \begin{cases}
	1 &\text{ if } \displaystyle\frac{\min(\lambda_i, \lambda_j)}{\max(\lambda_i, \lambda_j)} \ge \rho_1 \text{ et } \text{corr}({(i)}, f^{[j)}) \ge \rho_c\\
	0& \text{ sinon}
\end{cases}
$$
% paragraph  (end)

\paragraph{Nous (GG3)}
\label{par:nn}

Dans \cite{GNZ_10_SSA}, les auteurs introduisent le concept de w-corrélation pour deux séries $x, y$ de taille $N$ et pour une taille de fenêtre $K$:$$
\text{w-corr}(x, y) = \frac{\langle x|y\rangle_w}{\|x\|_w\|y\|_w}
$$avec $\langle x|y\rangle_w = \sum_{i=1}^n w_i x_i y_i$, $w_i = \min(i, N-i, K)$ et $\|x\|_w = \sqrt{\langle x|x\rangle_w}$. Deux séries sont séparables par la SSA si leur w-corrélation est nulle. Il est donc possible d'utiliser la valeur de la w-corrélation comme indicateur de similarité entre 2 composantes. On peut alors prendre une fonction de similarité identitque à celle de Abalov en remplaçant la corrélation par la w-corrélation. Ceci permet de filtrer les effets de bord qui peuvent apparaître dans la corrélation et ainsi d'obtenir un meilleur regroupement.
% paragraph nn (end)


\subsubsection{Periodigramme}

La fréquence des composantes obtenues peut aussi être utilisé comme un indicateur de similarité des séries. Dans \cite{GNZ_10_SSA}, les auteurs recommandent d'observer le périodigrame des composantes pour inférer le regroupement. Le périodigrame d'une série $f$ de longueur $N$ est définie comme:$$
\Pi_f(k) = \frac{1}{Z}\left|\sum_{n=1}^N f_n e^{-2i\pi n \frac{k}{N}}\right|^2
$$ où $Z$ est une constante de normalisation telle que le périodigramme est une norme unitaire.\\

\paragraph{Regroupement harmonique (HG)}\label{par:alex} Alexandrov \& al. proposent dans \cite{alexandrov_05_auto} une stratégie de regroupement spéciale pour extraire les harmoniques exponentiellement modulées. Ils proposent une fonction de similarité qui regroupe deux composantes successives $(j, j+1)$ si$$
\frac{1}{2}\max_{0\le k \le L/2}\left(\Pi_{U_j}(k) + \Pi_{U_{j+1}}(k)\right) \ge \rho_0
$$ pour $\rho_0\in \left[0, 1\right]$.\\

Ceci rend compte du fait que les composantes successives partage un même pique dans leur périodigramme.


% paragraph  (end)
\paragraph{Abalov method (GG2)}
\label{par:abalov}
\cite{abalov_14_auto}
On utilise
% paragraph abalov (end)
\paragraph{Alvarez}
\label{par:alva}
\cite{alvarez_2013_auto}
% paragraph alva (end)
\paragraph{Notre méthode}
\label{par:tomtom}


        
% paragraph tomtom (end)

\section{Méthode d'évaluation}
\label{sec:eval}

\subsection{Métrique d'évaluation}
\label{sub:}
Dans \cite{abalov_14_aut}, les auteurs proposent d'utiliser le coéfficient de determination $R^2$ pour évaluter la qualité d'un groupement. Ce coefficient rend compte de l'erreur commise par rapport à la variance de la composante. Pour une serie $f$ de moyenne $\bar f$ et pour un estimateur $\hat f$, le coefficient de determination est calculer suivant$$
R^2(f, \hat f) = 1 - \frac{\|f-\hat f\|^2}{\|f-\bar f\|^2}
$$ La métrique d'évaluation du grouping est alors calculer  en moyennant les valeurs minimales de $R^2$ pour chaque composante $c_i$ du signal d'origine et pour $$
\overline{ R^2} = \sum_{i=1}^n \min_k R^2(c_i, g_k)
$$

% subsection  (end)

\subsection{Séparabilité}
\label{sub:sep}
    L'évaluation de la stratégie de regroupement doit prendre en compte la qualité des composantes obtenue lors de la décomposition du signal. En effet, si les composantes que l'on essaie d'analyser ne sont pas séparables par l'analyse de la matrice de $K$-trajectoire, les stratégies de groupement ne pourront pas améliorer cette séparation.\\
    
    Il est donc important de rappeler ici les propriétés des composantes séparables. Deux signaux $f_1$ et $f_2$ sont dit séparables s'il existe $I_1, I_2 \subset \left \{ 1,\dots, K \right \}$ tel que $I_1\cap I_2 = \emptyset$ et $f_i = \mathcal H(\sum_{j \in I_i} \lambda_j U_j V_j^T)$. Ceci implique notamment l'orthogonalité de toutes les sous séries de longueur $K$ et $L$ de $f_1$ et $f_2$. Différentes illustrations de ces propriétés peuvent être trouvées dans \cite{GNZ_10_SSA}.
% subsection sep (end)


\subsection{Artificial signals}
\label{sub:}

% subsection  (end)
% section eval (end)

\section{Résultats} 

Comparaison avec la transformée en ondelettes empirique (EWT, \cite{gilles_13_EWT}).\\
%Pour le benchmark, je pense:\\
%\begin{itemize}
% \item Générer aléatoirement des signaux avec tendance, partie pseudo harmonique et bruit\\
% $$
% f_t = \sum_i c_i + n_i
% $$$$
% c_0 = trend; \hspace{1cm} c_i = cos(2\pi*w_i*t + u) 
% $$
%\item Faire la décomposition EWT et SSA / comparer les résultats\\
%\item Effectuer les grouping et comparé à la baseline du début\\

%\end{itemize}
%\vspace{1cm}
%Pour les mesures, il faudrait en utiliser deux:\\
%\begin{itemize}
%\item Erreur de reconstruction: $E_r = \sum_t (f_t-\widehat f_t)^2$\\
%où $\widehat f_t = \sum_{i \in I} f^{(i)}$ avec $I = \left \{ i \in [1..K] / \lambda_i > \mu \right \}$\\
%\item Grouping erreur: $E_g= \sum_i \min_j \| c_j - f^{(i)}\|^2$
%\end{itemize}

%Ou alors utiliser des metriques de Separation de source. \cite{vincent_06_BSS}

\bibliographystyle{plain} 
\bibliography{bib_dl}{}
\end{document}
